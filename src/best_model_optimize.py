import pandas as pd
import numpy as np
import os
import json
import joblib
import time
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

def load_data():
    """Ã–zellik mÃ¼hendisliÄŸi yapÄ±lmÄ±ÅŸ veriyi yÃ¼kle"""
    df = pd.read_csv(
        r"C:\Users\musta\MLOPS\ML_RentEstimate\ModelGelistirmeveOptimizasyon\data\processed\hamburgrentflat_features.csv"
    )
    return df

def prepare_features(df):
    """Modelleme iÃ§in Ã¶zellikleri hazÄ±rla (kategorik deÄŸiÅŸkenler one-hot encode edilecek)"""
    y = df['cold_price']

    # KullanÄ±lacak sÃ¼tunlar
    feature_columns = [
        'city', 'district', 'object_age', 'flat_area', 'room_count',
        'distance_to_centre', 'price_per_sqm', 'age_category', 'distance_category'
    ]

    # Mevcut sÃ¼tunlarÄ± filtrele
    available_features = [col for col in feature_columns if col in df.columns]
    X = df[available_features].copy()

    # Kategorik sÃ¼tunlarÄ± tespit et
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
    
    # One-hot encode (drop_first=True ile multicollinearity azaltÄ±lÄ±r)
    if categorical_cols:
        X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

    # Eksik deÄŸerleri doldur (numerik)
    X = X.fillna(X.mean())

    print(f"ğŸ”§ HazÄ±rlanan Ã¶zellikler: {X.columns.tolist()}")
    return X, y, X.columns.tolist()

# ------------------- OPTIMIZATION FUNCTIONS -------------------

def optimize_random_forest(X, y, cv_folds=5):
    print("ğŸŒ² Random Forest detaylÄ± optimizasyonu...")

    param_grid = {
        "n_estimators": [100, 200, 300, 500],
        "max_depth": [5, 10, 20, None],
        "min_samples_split": [2, 5, 10],
        "min_samples_leaf": [1, 2, 4],
        "max_features": ["sqrt", "log2", 0.5, 1.0],
        "bootstrap": [True, False],
    }

    rf = RandomForestRegressor(random_state=42)
    random_search = RandomizedSearchCV(
        rf, param_distributions=param_grid, n_iter=50, cv=cv_folds,
        scoring="r2", n_jobs=-1, verbose=1, random_state=42
    )

    start_time = time.time()
    random_search.fit(X, y)
    elapsed = time.time() - start_time

    return random_search.best_estimator_, random_search.best_params_, random_search.best_score_, elapsed

def optimize_gradient_boosting(X, y, cv_folds=5):
    print("ğŸš€ Gradient Boosting detaylÄ± optimizasyonu...")

    param_grid = {
        "n_estimators": [100, 200, 300],
        "learning_rate": [0.01, 0.05, 0.1, 0.2],
        "max_depth": [2, 3, 5],
        "min_samples_split": [2, 5, 10],
        "min_samples_leaf": [1, 2, 4],
        "subsample": [0.8, 0.9, 1.0],
        "max_features": ["sqrt", "log2", None],
    }

    gb = GradientBoostingRegressor(random_state=42)
    random_search = RandomizedSearchCV(
        gb, param_distributions=param_grid, n_iter=50, cv=cv_folds,
        scoring="r2", n_jobs=-1, verbose=1, random_state=42
    )

    start_time = time.time()
    random_search.fit(X, y)
    elapsed = time.time() - start_time

    return random_search.best_estimator_, random_search.best_params_, random_search.best_score_, elapsed

def optimize_knn(X, y, cv_folds=5):
    print("ğŸ¤ KNN Regressor detaylÄ± optimizasyonu...")

    param_grid = {
        "n_neighbors": [3, 5, 7, 10, 15],
        "weights": ["uniform", "distance"],
        "p": [1, 2],  # Manhattan vs Euclidean
    }

    knn = KNeighborsRegressor()
    grid_search = GridSearchCV(
        knn, param_grid, cv=cv_folds, scoring="r2", n_jobs=-1, verbose=1
    )

    start_time = time.time()
    grid_search.fit(X, y)
    elapsed = time.time() - start_time

    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_, elapsed

def optimize_decision_tree(X, y, cv_folds=5):
    print("ğŸŒ³ Decision Tree detaylÄ± optimizasyonu...")

    param_grid = {
        "max_depth": [5, 10, 20, None],
        "min_samples_split": [2, 5, 10, 20],
        "min_samples_leaf": [1, 2, 4, 10],
        "max_features": ["sqrt", "log2", None],
    }

    dt = DecisionTreeRegressor(random_state=42)
    grid_search = GridSearchCV(
        dt, param_grid, cv=cv_folds, scoring="r2", n_jobs=-1, verbose=1
    )

    start_time = time.time()
    grid_search.fit(X, y)
    elapsed = time.time() - start_time

    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_, elapsed

# ------------------- FINAL EVALUATION -------------------

def final_evaluation(model, X, y, model_name, cv_folds=10):
    print(f"\nğŸ¯ {model_name} final deÄŸerlendirmesi ({cv_folds} fold CV)...")

    cv_r2 = cross_val_score(model, X, y, cv=cv_folds, scoring="r2")
    cv_rmse = np.sqrt(-cross_val_score(model, X, y, cv=cv_folds, scoring="neg_mean_squared_error"))
    cv_mae = -cross_val_score(model, X, y, cv=cv_folds, scoring="neg_mean_absolute_error")

    results = {
        "r2_mean": float(cv_r2.mean()), "r2_std": float(cv_r2.std()),
        "rmse_mean": float(cv_rmse.mean()), "rmse_std": float(cv_rmse.std()),
        "mae_mean": float(cv_mae.mean()), "mae_std": float(cv_mae.std())
    }

    print("ğŸ“Š Final SonuÃ§lar:")
    print(f"   RÂ²:   {cv_r2.mean():.4f} (Â±{cv_r2.std()*2:.4f})")
    print(f"   RMSE: {cv_rmse.mean():.2f} (Â±{cv_rmse.std()*2:.2f})")
    print(f"   MAE:  {cv_mae.mean():.2f} (Â±{cv_mae.std()*2:.2f})")

    return results

# ------------------- MAIN -------------------

def main():
    print("ğŸ¯ En Ä°yi Model DetaylÄ± Optimizasyonu")
    print("="*50)

    df = load_data()
    X, y, feature_names = prepare_features(df)

    print(f"ğŸ“Š Veri boyutu: {X.shape}")
    print(f"ğŸ”§ Ã–zellikler: {feature_names}")

    # Ã–nce best_model.pkl'i yÃ¼kle
    best_model_path = r"C:\Users\musta\MLOPS\ML_RentEstimate\ModelGelistirmeveOptimizasyon\src\models\best_model.pkl"
    if not os.path.exists(best_model_path):
        print("âŒ best_model.pkl bulunamadÄ±! Ã–nce model_gelistirme.py Ã§alÄ±ÅŸtÄ±rÄ±n.")
        return

    best_model = joblib.load(best_model_path)
    best_model_name = type(best_model.named_steps["model"]).__name__
    print(f"ğŸ“¦ En iyi model: {best_model_name}")

    cv_folds = 5
    if best_model_name == "RandomForestRegressor":
        optimized_model, best_params, best_score, elapsed = optimize_random_forest(X, y, cv_folds)
    elif best_model_name == "GradientBoostingRegressor":
        optimized_model, best_params, best_score, elapsed = optimize_gradient_boosting(X, y, cv_folds)
    elif best_model_name == "KNeighborsRegressor":
        optimized_model, best_params, best_score, elapsed = optimize_knn(X, y, cv_folds)
    elif best_model_name == "DecisionTreeRegressor":
        optimized_model, best_params, best_score, elapsed = optimize_decision_tree(X, y, cv_folds)
    elif best_model_name == "LinearRegression":
        print("ğŸ“ˆ Linear Regression iÃ§in detaylÄ± optimizasyon yok (parametre yok).")
        return
    else:
        print(f"âŒ {best_model_name} iÃ§in detaylÄ± optimizasyon tanÄ±mlÄ± deÄŸil!")
        return

    print(f"\nğŸš€ Optimizasyon SonuÃ§larÄ±:")
    print(f"   En iyi RÂ² (CV): {best_score:.4f}")
    print(f"   SÃ¼re: {elapsed:.2f} sn")
    print(f"   Parametreler: {best_params}")

    # Final deÄŸerlendirme
    final_results = final_evaluation(optimized_model, X, y, best_model_name, cv_folds=10)

    # Kaydetme
    os.makedirs("models/detailed_optimized", exist_ok=True)
    os.makedirs("results", exist_ok=True)

    joblib.dump(optimized_model, f"models/detailed_optimized/{best_model_name}_detailed.pkl")

    detailed_results = {
        "model_name": best_model_name,
        "best_params": best_params,
        "best_score_cv": best_score,
        "optimization_time_sec": elapsed,
        "final_evaluation": final_results,
        "features_used": feature_names,
    }

    with open("results/detailed_optimization_report.json", "w") as f:
        json.dump(detailed_results, f, indent=2)

    print("\nâœ… DetaylÄ± optimizasyon tamamlandÄ±!")
    print(f"ğŸ“ Model kaydedildi: models/detailed_optimized/{best_model_name}_detailed.pkl")
    print(f"ğŸ“Š Rapor: results/detailed_optimization_report.json")

if __name__ == "__main__":
    main()
